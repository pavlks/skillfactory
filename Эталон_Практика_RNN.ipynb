{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "hsP7cV1_arhs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torchtext import datasets\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import random\n",
    "\n",
    "from gensim.models import FastText\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "sNRfW260a3jg"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "uyk3BCHza5ru"
   },
   "outputs": [],
   "source": [
    "train_data, _, test_data = datasets.UDPOS()\n",
    "train_data = [d for d in train_data]\n",
    "test_data = [d for d in test_data]\n",
    "\n",
    "train_tokens = [ [w.lower() for w in d[0]] for d in train_data]\n",
    "train_tags = [ d[1] for d in train_data]\n",
    "\n",
    "test_tokens = [[w.lower() for w in d[0]] for d in test_data]\n",
    "test_tags = [d[1] for d in test_data]\n",
    "\n",
    "tag2num = { t:i for i, t in enumerate(np.unique([tag for tags in train_tags for tag in tags])) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "pBDDAUdhbxCq"
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "word_to_ix = {}\n",
    "for tokens in train_tokens:\n",
    "    for word in tokens:\n",
    "        word = stemmer.stem(word)\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "word_to_ix[\"UNK\"] =  len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hkWDYVab5PT",
    "outputId": "dfe2e0dd-5484-4a4b-ff84-06baedd5c212"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([12543, 20]), torch.Size([12543, 20]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 20\n",
    "pad_inds = len(tag2num)\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(w) for w in seq]\n",
    "    idxs = [to_ix[w] if w in to_ix else to_ix[\"UNK\"] for w in stemmed_words ]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "def prepare_data_for_inner_embeddings(all_tokens, all_tags, word_to_ix, tag2num, max_len, pad_tags):\n",
    "    all_tags = [np.array([tag2num[tag]  for tag in tags]) for tags in all_tags]\n",
    "    \n",
    "    all_tokens = [tokens[:max_len] for tokens in all_tokens]\n",
    "    all_tags = [tags[:max_len] for tags in all_tags]\n",
    "    \n",
    "    all_ids = []\n",
    "    for tokens in all_tokens:\n",
    "        ids = prepare_sequence(tokens, word_to_ix)\n",
    "        all_ids.append(ids)\n",
    "        \n",
    "    X_vecs = []\n",
    "    Y_vecs = []\n",
    "\n",
    "    for ids, tags in zip(all_ids, all_tags):\n",
    "        X_vecs.append(torch.tensor(ids, dtype=torch.long))\n",
    "        Y_vecs.append(torch.tensor(tags, dtype=torch.long))\n",
    "        \n",
    "    # в качестве заполнителя X используем новый индекс len(word_to_ix)\n",
    "    X = pad_sequence(X_vecs, batch_first=True, padding_value=len(word_to_ix))\n",
    "\n",
    "    # в качестве заполнителя Y используем pad_tags\n",
    "    Y = pad_sequence(Y_vecs, batch_first=True, padding_value=pad_tags)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "X_train, Y_train = prepare_data_for_inner_embeddings(train_tokens, train_tags, word_to_ix, tag2num, max_len, pad_inds)\n",
    "\n",
    "X_train.size(), Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYNHAQxZcHhS",
    "outputId": "c3acb0b5-1abf-4169-eb54-d8e090969972"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2077, 20]), torch.Size([2077, 20]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, Y_test = prepare_data_for_inner_embeddings(test_tokens, test_tags, word_to_ix, tag2num, max_len, pad_inds)\n",
    "\n",
    "X_test.size(), Y_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeBb8AbNcdX_",
    "outputId": "2fc5233f-9d8f-45c2-9804-2e74a53ee3ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,  ...,    14,    15,    11],\n",
      "        [   23,    24,     6,  ...,    37, 12121, 12121],\n",
      "        [   38,     3,    39,  ..., 12121, 12121, 12121],\n",
      "        ...,\n",
      "        [ 3083,    43,    28,  ...,   211,    29,    25],\n",
      "        [   11,  4206,    13,  ...,    17,   368,    42],\n",
      "        [  112,    28,   387,  ...,   132,    43,  1054]])\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfjixGEdceuN",
    "outputId": "f02de312-5b79-4c4c-a772-4999b06dfdfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12, 11,  ...,  7,  1,  5],\n",
      "        [12,  5,  7,  ..., 12, 17, 17],\n",
      "        [11, 12,  0,  ..., 17, 17, 17],\n",
      "        ...,\n",
      "        [ 2, 10,  3,  ...,  2,  3,  5],\n",
      "        [ 5,  7,  1,  ...,  1,  7, 10],\n",
      "        [10,  3,  2,  ...,  7, 10,  2]])\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "W8RSqbmOckWA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "bs = 128\n",
    "data = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "M5lgGR7Dcl0X"
   },
   "outputs": [],
   "source": [
    "class BiLSTMPOSTagger(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # padding_idx=pad_idx - это номер id \"заполнителя\". \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        # добавляем в параметры модели то, что первая размерность отвечает за батчи - после этого мы сможем не использовать метод view в обработке (в forward)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout if n_layers > 1 else 0, batch_first = True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    # меняем функцию, применяем эмбеддинг при обработке текста\n",
    "    def forward(self, text):\n",
    "        outputs, (hidden, cell) = self.lstm(self.embedding(text))\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "XHtLZSe8dBWV"
   },
   "outputs": [],
   "source": [
    "def train_on_epoch(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input, b_tags = batch\n",
    "        \n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input) \n",
    "\n",
    "        # здесь функция view нужна!\n",
    "        # outputs = [batch size, sent len, out dim]\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])       \n",
    "        # outputs = [batch size * sent len, out dim]\n",
    "\n",
    "        # b_tags = [batch size, sent len]\n",
    "        b_tags = b_tags.view(-1)\n",
    "        # b_tags = [batch size * sent len]\n",
    "        \n",
    "        loss = criterion(outputs, b_tags)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def predict_on_dataloader(model, dataloaded):\n",
    "    model.eval()\n",
    "        \n",
    "    all_outputs = []\n",
    "    all_tags = []\n",
    "    for batch in dataloaded:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input, b_tags = batch\n",
    "        outputs = model(b_input)  \n",
    "        \n",
    "        outputs = outputs.view(-1, outputs.shape[-1])       \n",
    "        b_tags = b_tags.view(-1)\n",
    "\n",
    "        all_outputs.append(outputs)\n",
    "        all_tags.append(b_tags)\n",
    "\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_tags = torch.cat(all_tags)\n",
    "    \n",
    "    return all_outputs, all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9HPx3ywdDUj",
    "outputId": "08d303bc-3b37-464e-82d8-8d36101a73a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "8uDf2IvsdEeg"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(word_to_ix)+1\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(tag2num)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "PAD_IDX = len(word_to_ix)\n",
    "\n",
    "model = BiLSTMPOSTagger(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_inds)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWu61Ea-dKbc",
    "outputId": "85b1f644-eb8e-4276-d83f-f1cfd2171e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tLoss 5.557459261468461e-06, accuracy: 0.7129221326346734, f1-macro: 0.5302582019515593\n",
      "1:\tLoss 3.632146791607471e-06, accuracy: 0.8054761157954944, f1-macro: 0.7014959554800455\n",
      "2:\tLoss 2.7419912671908238e-06, accuracy: 0.8531891732319784, f1-macro: 0.7650589188356605\n",
      "3:\tLoss 2.1752669233417644e-06, accuracy: 0.8841983554432123, f1-macro: 0.8106203037607905\n",
      "4:\tLoss 1.7598667550182433e-06, accuracy: 0.9075259691138213, f1-macro: 0.8493931588113233\n",
      "5:\tLoss 1.4480388077201148e-06, accuracy: 0.9242667453889063, f1-macro: 0.8761806433682885\n",
      "6:\tLoss 1.188654476183766e-06, accuracy: 0.9391932200471104, f1-macro: 0.9015598871403027\n",
      "7:\tLoss 9.759769824341272e-07, accuracy: 0.9508416514449836, f1-macro: 0.9203174809700494\n",
      "8:\tLoss 7.918361970935309e-07, accuracy: 0.9610570920742695, f1-macro: 0.9369362432244044\n",
      "9:\tLoss 6.472855765843729e-07, accuracy: 0.9684742030910779, f1-macro: 0.9454437652426189\n",
      "10:\tLoss 5.360378329265314e-07, accuracy: 0.9743599205397394, f1-macro: 0.9554123152100895\n",
      "11:\tLoss 4.4043151091963887e-07, accuracy: 0.9793784633172814, f1-macro: 0.9636578041050923\n",
      "12:\tLoss 3.5230081143723473e-07, accuracy: 0.9839726440217225, f1-macro: 0.9706560872437767\n",
      "13:\tLoss 2.8273610082422806e-07, accuracy: 0.9875397455057596, f1-macro: 0.9754215289382269\n",
      "14:\tLoss 2.1584102465015373e-07, accuracy: 0.9908854406907877, f1-macro: 0.9823320168888879\n",
      "15:\tLoss 1.752713722008951e-07, accuracy: 0.9928903977318154, f1-macro: 0.9859956810042213\n",
      "16:\tLoss 1.4519742623383844e-07, accuracy: 0.993991279051889, f1-macro: 0.9879460583404279\n",
      "17:\tLoss 1.3816421873338676e-07, accuracy: 0.9942495864007331, f1-macro: 0.990603503837728\n",
      "18:\tLoss 1.1936538346889425e-07, accuracy: 0.995264365271192, f1-macro: 0.9920317996720996\n",
      "19:\tLoss 1.0130832079985557e-07, accuracy: 0.9957625294439627, f1-macro: 0.9928147559269649\n",
      "20:\tLoss 8.499057235957194e-08, accuracy: 0.9966666051649169, f1-macro: 0.9944395574576083\n",
      "21:\tLoss 7.038426668886465e-08, accuracy: 0.9974292268615043, f1-macro: 0.995379520802346\n",
      "22:\tLoss 5.61909466222886e-08, accuracy: 0.9979765924340548, f1-macro: 0.996436951459282\n",
      "23:\tLoss 5.101150045824704e-08, accuracy: 0.9981426471583117, f1-macro: 0.9966499090495655\n",
      "24:\tLoss 4.094744933381232e-08, accuracy: 0.9985116576566603, f1-macro: 0.9973839383354999\n",
      "25:\tLoss 2.7687193092075814e-08, accuracy: 0.9990959242790457, f1-macro: 0.9983749678084938\n",
      "26:\tLoss 2.241512988589394e-08, accuracy: 0.9994218835525871, f1-macro: 0.9989172311170255\n",
      "27:\tLoss 1.793312889795067e-08, accuracy: 0.9995141361771742, f1-macro: 0.9991769604070256\n",
      "28:\tLoss 1.7566937961642124e-08, accuracy: 0.9995510372270091, f1-macro: 0.9993669605237239\n",
      "29:\tLoss 1.7217300358055823e-08, accuracy: 0.9994895354772844, f1-macro: 0.999059952860379\n",
      "30:\tLoss 1.4296052397846984e-08, accuracy: 0.9996063888017614, f1-macro: 0.9994887407914405\n",
      "31:\tLoss 1.1648032516075196e-08, accuracy: 0.9997232421262385, f1-macro: 0.9996487649056521\n",
      "32:\tLoss 1.1328959152133354e-08, accuracy: 0.9997109417762935, f1-macro: 0.9995183240085013\n",
      "33:\tLoss 9.858380977183029e-09, accuracy: 0.9997908940509358, f1-macro: 0.9997246489749656\n",
      "34:\tLoss 1.0115334237016735e-08, accuracy: 0.9997047916013211, f1-macro: 0.9995524448275387\n",
      "35:\tLoss 9.853463663639067e-09, accuracy: 0.9997478428261284, f1-macro: 0.9996255921092742\n",
      "36:\tLoss 7.942107182584672e-09, accuracy: 0.9997908940509358, f1-macro: 0.9996922249071252\n",
      "37:\tLoss 8.845724404128354e-09, accuracy: 0.9997601431760733, f1-macro: 0.9996890749621218\n",
      "38:\tLoss 7.831021575670558e-09, accuracy: 0.9997601431760733, f1-macro: 0.9996998729257046\n",
      "39:\tLoss 6.5719695042147965e-09, accuracy: 0.9998339452757431, f1-macro: 0.9997312922283131\n",
      "40:\tLoss 6.568712535765252e-09, accuracy: 0.9998216449257982, f1-macro: 0.9997850598468119\n",
      "41:\tLoss 7.38761134694162e-09, accuracy: 0.9997662933510458, f1-macro: 0.9996037365988037\n",
      "42:\tLoss 6.217156836228999e-09, accuracy: 0.9998523958006605, f1-macro: 0.9997469325558278\n",
      "43:\tLoss 6.383063902191969e-09, accuracy: 0.9997785937009908, f1-macro: 0.999739563997035\n",
      "44:\tLoss 6.204100323446869e-09, accuracy: 0.9998154947508257, f1-macro: 0.9997775361359085\n",
      "45:\tLoss 6.290572871581028e-09, accuracy: 0.9997785937009908, f1-macro: 0.999745799964632\n",
      "46:\tLoss 6.573909795377309e-09, accuracy: 0.9997601431760733, f1-macro: 0.9997685222350166\n",
      "47:\tLoss 6.352237615844381e-09, accuracy: 0.9997478428261284, f1-macro: 0.9996689258127345\n",
      "48:\tLoss 4.999866489154269e-09, accuracy: 0.9998277951007706, f1-macro: 0.9998188043704446\n",
      "49:\tLoss 8.53087457434432e-09, accuracy: 0.9996801909014311, f1-macro: 0.9996008630097861\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for e in range(epochs):\n",
    "    train_on_epoch(model, dataloader, optimizer)    \n",
    "    \n",
    "    all_outputs, all_tags = predict_on_dataloader(model, dataloader)\n",
    "    loss = criterion(all_outputs, all_tags).item()\n",
    "    all_outputs = all_outputs.detach().cpu().numpy()\n",
    "    all_tags = all_tags.detach().cpu().numpy()\n",
    "    \n",
    "    mask = all_tags != pad_inds\n",
    "    loss = loss/len(all_tags[mask]) \n",
    "    all_tags = all_tags[mask]\n",
    "    all_preds = np.argmax(all_outputs, axis=1)[mask]\n",
    "    \n",
    "    print(f\"{e}:\\tLoss {loss}, \"\n",
    "          f\"accuracy: {accuracy_score(all_tags, all_preds)}, \"\n",
    "          f\"f1-macro: {f1_score(all_tags, all_preds, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "8kcXubKVdVov"
   },
   "outputs": [],
   "source": [
    "def count_metrics(model, dataloader):\n",
    "  y_pred, y_true = predict_on_dataloader(model, dataloader)\n",
    "\n",
    "  y_pred = y_pred.detach().cpu().numpy()\n",
    "  y_true = y_true.detach().cpu().numpy()\n",
    "\n",
    "  mask = y_true != pad_inds\n",
    "  y_true = y_true[mask]\n",
    "  y_pred = np.argmax(y_pred, axis=1)[mask]\n",
    "\n",
    "  print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25kR8EZsdavw",
    "outputId": "8eee9a1c-d0fc-45fe-f127-75b4222a6b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9962\n",
      "           1       1.00      1.00      1.00     13578\n",
      "           2       1.00      1.00      1.00      8547\n",
      "           3       1.00      1.00      1.00     10404\n",
      "           4       1.00      1.00      1.00      5202\n",
      "           5       1.00      1.00      1.00     13014\n",
      "           6       1.00      1.00      1.00       649\n",
      "           7       1.00      1.00      1.00     27080\n",
      "           8       1.00      1.00      1.00      3339\n",
      "           9       1.00      1.00      1.00      4484\n",
      "          10       1.00      1.00      1.00     15619\n",
      "          11       1.00      1.00      1.00     10523\n",
      "          12       1.00      1.00      1.00     16990\n",
      "          13       1.00      1.00      1.00      3134\n",
      "          14       1.00      1.00      1.00       484\n",
      "          15       1.00      1.00      1.00     18849\n",
      "          16       1.00      1.00      1.00       739\n",
      "\n",
      "    accuracy                           1.00    162597\n",
      "   macro avg       1.00      1.00      1.00    162597\n",
      "weighted avg       1.00      1.00      1.00    162597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_metrics(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAOUiigWdY7m",
    "outputId": "323b0387-a4d2-4891-c31b-4fb87060b0f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81      1466\n",
      "           1       0.91      0.97      0.93      1656\n",
      "           2       0.84      0.87      0.85      1066\n",
      "           3       0.97      0.98      0.97      1336\n",
      "           4       0.99      0.99      0.99       599\n",
      "           5       0.98      0.99      0.98      1607\n",
      "           6       0.94      0.78      0.85       115\n",
      "           7       0.83      0.87      0.85      3446\n",
      "           8       0.82      0.70      0.76       448\n",
      "           9       0.94      0.97      0.96       546\n",
      "          10       0.98      0.98      0.98      1923\n",
      "          11       0.76      0.68      0.72      1773\n",
      "          12       0.99      0.99      0.99      2467\n",
      "          13       0.92      0.78      0.84       330\n",
      "          14       0.88      0.79      0.83        81\n",
      "          15       0.91      0.89      0.90      2306\n",
      "          16       0.56      0.16      0.25       114\n",
      "\n",
      "    accuracy                           0.90     21279\n",
      "   macro avg       0.88      0.84      0.85     21279\n",
      "weighted avg       0.90      0.90      0.90     21279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = TensorDataset(X_test, Y_test)\n",
    "test_dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)\n",
    "count_metrics(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "W32kZg1qdbSj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "My POS_task_embedding.ipynb_3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
